{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataCollection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mzaman202006/DA_project/blob/main/DataCollection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFbyeEmxL5qT",
        "outputId": "bd27bd2f-0b83-4c73-f283-2a83efbc2e7f"
      },
      "source": [
        "!pip3 install beautifulsoup4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (4.6.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJZm_VSZMEpz",
        "outputId": "ba911f93-b4a7-42ce-df3e-f346be895de8"
      },
      "source": [
        "pip install requests bs4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2020.12.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAPaYY69KrKl"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from openpyxl import load_workbook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_e192qpOCvUV",
        "outputId": "80ef88d7-b271-44e1-b5e1-86f285a0dca5"
      },
      "source": [
        "import pandas\n",
        "from google.colab import drive\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZHRNUbbRpFI"
      },
      "source": [
        "# Collect Movie Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01dogHEs7zF7"
      },
      "source": [
        "url= 'https://www.imdb.com/title/tt8380776/'\n",
        "r = requests.get(url)\n",
        "movies_soup = BeautifulSoup(r.content, 'html.parser')\n",
        "title = movies_soup.find('div', attrs={'class': 'title_wrapper'})\n",
        "year =''\n",
        "final_name =''\n",
        "genre_name_str =''\n",
        "#print(title)\n",
        "release_date_final = ''\n",
        "final_rating = ''\n",
        "final_plot= ''\n",
        "\n",
        "if(title is not None):\n",
        "  year = (title.find('h1').find('span').text) [1:-1]\n",
        "  \n",
        "  #print(year)\n",
        "  title_name = (title.find('h1').text)\n",
        "\n",
        "  final_name = title_name[:len(title_name)-7]\n",
        "\n",
        "  #print(final_name)\n",
        "\n",
        "  genre_name = [tag.text for tag in title.find_all('a', attrs={'class': ''})if tag.attrs['href'].startswith('/search/title?genres') ] \n",
        "  #print(genre_name)\n",
        "  genre_name_str = ','.join(genre_name)\n",
        "\n",
        "  release_date = [tag.text for tag in title.find_all('a', attrs={'class': ''})if tag.attrs['href'].endswith('releaseinfo') ] \n",
        "  release_date_final = (release_date[0].strip())\n",
        "\n",
        "rating = movies_soup.find('div', attrs={'class': 'ratingValue'})\n",
        "#print(rating.find('strong').attrs['title'])\n",
        "if(rating is not None):\n",
        " final_rating  = rating.find('span', attrs={'itemprop': 'ratingValue'}).text\n",
        " #print(final_rating)\n",
        "\n",
        "plot  = movies_soup.find('div', attrs={'class': 'plot_summary_wrapper'})\n",
        "if(plot is not None):\n",
        " final_plot_0 = plot.find('div', attrs={'class': 'summary_text'})\n",
        " final_plot = final_plot_0.text.strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZdAwEzY7-oH"
      },
      "source": [
        "#Review Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSoCqP6QvqLU"
      },
      "source": [
        "\n",
        "\n",
        "#base_url = \"https://www.imdb.com\"\n",
        "review_links_ = url+ 'reviews?spoiler=hide&sort=helpfulnessScore&dir=desc&ratingFilter=0'\n",
        "#print(\"There are a total of \" + str(len(movie_links)) + \" movie user reviews\")\n",
        "#print(\"Displaying 10 user reviews links\")\n",
        "#movie_links_\n",
        "\n",
        "# get a list of soup objects\n",
        "index =0\n",
        "rows = []\n",
        "\n",
        "   \n",
        "soup = BeautifulSoup(requests.get(review_links_).content, 'html.parser')\n",
        "total_review = soup.find('div', attrs={'class': 'header'}).find('span').text\n",
        "total_review_count = re.findall('[0-9]+', total_review.replace(\",\", \"\"))\n",
        "Review_tags_ = soup.findAll('div', attrs={'class': 'review-container'})\n",
        "#print(first_movie_tags_)\n",
        "if(Review_tags_ is not None):\n",
        "  for movie_review_holder in Review_tags_:\n",
        "    review = movie_review_holder.find('div', attrs={'class': 'text show-more__control'})\n",
        "    #print(review.text)\n",
        "    title = movie_review_holder.find('a', attrs={'class': 'title'})\n",
        "    #print(title.text)\n",
        "    #print(title.attrs['href'])\n",
        "\n",
        "    r_date = movie_review_holder.find('span', attrs={'class': 'review-date'})\n",
        "    #print(r_date.text)\n",
        "\n",
        "    user_l = movie_review_holder.find('span', attrs={'class': 'display-name-link'})\n",
        "    user_a = user_l.findChildren(\"a\" , recursive=False)\n",
        "    #print(user_a[0])\n",
        "    rating_final =0\n",
        "    rating =  movie_review_holder.find('span', attrs={'class': 'rating-other-user-rating'})\n",
        "    if (rating is not None):\n",
        "      rr_f =rating.findAll('span')\n",
        "      rating_final =  rr_f[0].text\n",
        "    #print(rating_final)\n",
        "    \n",
        "    help = movie_review_holder.find('div', attrs={'class': 'actions'}).text\n",
        "    #print(help)\n",
        "    numbers = re.findall('[0-9]+', help.strip().replace(\",\", \"\"))\n",
        "    #print(total_review_count[0])\n",
        "    numbers_helpful_str = '/'.join(numbers)\n",
        "    #print(numbers_helpful_str)\n",
        "    #print(','.join(total_review_count))\n",
        "    rows.append([review_links_,year,final_name,genre_name_str,release_date_final,final_rating,final_plot,\n",
        "    total_review_count[0],title.text,title.attrs['href'],review.text ,r_date.text,user_a[0],rating_final,numbers_helpful_str])\n",
        "\n",
        "df = pd. DataFrame(rows, columns=[\"URL\", \"YEAR\",\"MOVIE\",\"Genre\",\"Release date\",\"rating\",\"plot\",\n",
        "                                    \"total review\",\"Title\",\"LINK\",\"REVIEW\",\"date\",\"Author\",\"RATING\",\"helpful\"])\n",
        "\n",
        "#print(df['REVIEW'])\n",
        "#print(df['Title'])\n",
        "#print(df['date'])\n",
        "#print(df['RATING'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L4UlQay8G6Z"
      },
      "source": [
        "#print(rows)\n",
        "writer = pd.ExcelWriter('/content/sample_data/data.xlsx', engine='openpyxl')\n",
        "# try to open an existing workbook\n",
        "writer.book = load_workbook('/content/sample_data/data.xlsx')\n",
        "# copy existing sheets\n",
        "writer.sheets = dict((ws.title, ws) for ws in writer.book.worksheets)\n",
        "# read existing file\n",
        "reader = pd.read_excel(r'/content/sample_data/data.xlsx')\n",
        "# write out the new sheet\n",
        "df.to_excel(writer,index=False,header=False,startrow=len(reader)+1)\n",
        "\n",
        "writer.close()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4zo8MDs77Lh"
      },
      "source": [
        ""
      ]
    }
  ]
}